{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./inputs/mnist/train-images-idx3-ubyte.gz\n",
      "Extracting ./inputs/mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting ./inputs/mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./inputs/mnist/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('./inputs/mnist')\n",
    "# Resetting default graph, starting from scratch\n",
    "tf.reset_default_graph()\n",
    "\n",
    "epochs = 1\n",
    "batch_size = 64\n",
    "n_noise = 200\n",
    "learning_rate=0.00015\n",
    "\n",
    "real_images = tf.placeholder(dtype=tf.float32, shape=[None, 28, 28, 1], name='real_images')\n",
    "noise = tf.placeholder(dtype=tf.float32, shape=[None, n_noise])\n",
    "\n",
    "# The keep_prob variable will be used by our dropout layers, which we introduce for more stable learning outcome\n",
    "keep_prob = tf.placeholder(dtype=tf.float32, name='keep_prob')\n",
    "is_training = tf.placeholder(dtype=tf.bool, name='is_training')\n",
    "\n",
    "# Leaky Relu activation\n",
    "# https://en.wikipedia.org/wiki/Rectifier_%28neural_networks%29#Potential_problems\n",
    "def lrelu(x):\n",
    "    return tf.maximum(x, tf.multiply(x, 0.2))\n",
    "\n",
    "# Binary cross entropy for descriminators\n",
    "def binary_cross_entropy(x, z):\n",
    "    eps = 1e-12\n",
    "    return (-(x * tf.log(z + eps) + (1. - x) * tf.log(1. - z + eps)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The descriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# It takes either real or fake MNIST image 28 x 28 in grayscale\n",
    "# we use a sigmoid to make sure our output can be interpreted \n",
    "# as the probability the input image is a real MNIST character.\n",
    "def discriminator(real_images, reuse=None, keep_prob=keep_prob):\n",
    "    activation=lrelu\n",
    "    with tf.variable_scope('disc', reuse=reuse):\n",
    "        x = tf.reshape(real_images, shape=[-1, 28, 28, 1])\n",
    "        x = tf.layers.conv2d(x, kernel_size=5, filters=64, strides=2, padding='same', activation=activation)\n",
    "        x = tf.layers.dropout(x, keep_prob)\n",
    "        x = tf.layers.conv2d(x, kernel_size=5, filters=64, strides=1, padding='same', activation=activation)\n",
    "        x = tf.layers.dropout(x, keep_prob)\n",
    "        x = tf.layers.conv2d(x, kernel_size=5, filters=64, strides=1, padding='same', activation=activation)\n",
    "        x = tf.layers.dropout(x, keep_prob)\n",
    "        x = tf.layers.flatten(x)\n",
    "        x = tf.layers.dense(x, units=128, activation=activation)\n",
    "        x = tf.layers.dense(x, units=1, activation=tf.nn.sigmoid)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# z => noise\n",
    "def generator(z, keep_prob=keep_prob, is_training=is_training):\n",
    "    activation = lrelu\n",
    "    momentum = 0.99\n",
    "    with tf.variable_scope('gen', reuse=None):\n",
    "        x = z\n",
    "        d1 = 4\n",
    "        d2 = 1\n",
    "        print('checking units ', (d1 * d1 * d2))\n",
    "        x = tf.layers.dense(x, units=d1 * d1 * d2, activation=activation)\n",
    "        x = tf.layers.dropout(x, keep_prob)\n",
    "        # https://www.tensorflow.org/api_docs/python/tf/contrib/layers/batch_norm\n",
    "        x = tf.contrib.layers.batch_norm(x, is_training=is_training, decay=momentum)\n",
    "        x = tf.reshape(x, shape=[-1, d1, d1, d2])\n",
    "        x = tf.image.resize_images(x, size=[7, 7])\n",
    "        x = tf.layers.conv2d_transpose(x, kernel_size=5, filters=64, strides=2, padding='same', activation=activation)\n",
    "        x = tf.layers.dropout(x, keep_prob)\n",
    "        x = tf.contrib.layers.batch_norm(x, is_training=is_training, decay=momentum)\n",
    "        x = tf.layers.conv2d_transpose(x, kernel_size=5, filters=64, strides=2, padding='same', activation=activation)\n",
    "        x = tf.layers.dropout(x, keep_prob)\n",
    "        x = tf.contrib.layers.batch_norm(x, is_training=is_training, decay=momentum)\n",
    "        x = tf.layers.conv2d_transpose(x, kernel_size=5, filters=64, strides=1, padding='same', activation=activation)\n",
    "        x = tf.layers.dropout(x, keep_prob)\n",
    "        x = tf.contrib.layers.batch_norm(x, is_training=is_training, decay=momentum)\n",
    "        x = tf.layers.conv2d_transpose(x, kernel_size=5, filters=1, strides=1, padding='same', activation=tf.nn.sigmoid)\n",
    "        # x = tf.layers.dense(x, units=784, activation=tf.nn.tanh)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss functions and optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('checking units ', 16)\n"
     ]
    }
   ],
   "source": [
    "g = generator(noise, keep_prob, is_training)\n",
    "d_real = discriminator(real_images)\n",
    "d_fake = discriminator(g, reuse=True)\n",
    "\n",
    "vars_g = [var for var in tf.trainable_variables() if 'gen' in var.name]\n",
    "vars_d = [var for var in tf.trainable_variables() if 'disc' in var.name]\n",
    "\n",
    "# Applying regularizers\n",
    "d_reg = tf.contrib.layers.apply_regularization(tf.contrib.layers.l2_regularizer(1e-6), vars_d)\n",
    "g_reg = tf.contrib.layers.apply_regularization(tf.contrib.layers.l2_regularizer(1e-6), vars_g)\n",
    "\n",
    "loss_d_real = binary_cross_entropy(tf.ones_like(d_real), d_real)\n",
    "loss_d_fake = binary_cross_entropy(tf.zeros_like(d_fake), d_fake)\n",
    "loss_g = tf.reduce_mean(binary_cross_entropy(tf.ones_like(d_fake), d_fake))\n",
    "loss_d = tf.reduce_mean(0.5 * (loss_d_real + loss_d_fake))\n",
    "\n",
    "# optimizer_d = tf.train.AdamOptimizer(learning_rate).minimize(loss_d, var_list=vars_d)\n",
    "# optimizer_g = tf.train.AdamOptimizer(learning_rate).minimize(loss_g, var_list=vars_g)\n",
    "update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "with tf.control_dependencies(update_ops):\n",
    "    optimizer_d = tf.train.RMSPropOptimizer(learning_rate=0.00015).minimize(loss_d + d_reg, var_list=vars_d)\n",
    "    optimizer_g = tf.train.RMSPropOptimizer(learning_rate=0.00015).minimize(loss_g + g_reg, var_list=vars_g)\n",
    "\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Training GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 28, 28, 1)\n",
      "[[[[ 0.49791801]\n",
      "   [ 0.49748281]\n",
      "   [ 0.49700615]\n",
      "   ..., \n",
      "   [ 0.49885151]\n",
      "   [ 0.49746954]\n",
      "   [ 0.49890342]]\n",
      "\n",
      "  [[ 0.49799049]\n",
      "   [ 0.49680182]\n",
      "   [ 0.49604493]\n",
      "   ..., \n",
      "   [ 0.49735928]\n",
      "   [ 0.49867314]\n",
      "   [ 0.49852818]]\n",
      "\n",
      "  [[ 0.49831033]\n",
      "   [ 0.49669075]\n",
      "   [ 0.49577042]\n",
      "   ..., \n",
      "   [ 0.49795324]\n",
      "   [ 0.49842829]\n",
      "   [ 0.49782127]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.49652216]\n",
      "   [ 0.49823493]\n",
      "   [ 0.49667582]\n",
      "   ..., \n",
      "   [ 0.49679911]\n",
      "   [ 0.4973315 ]\n",
      "   [ 0.4979662 ]]\n",
      "\n",
      "  [[ 0.49943677]\n",
      "   [ 0.49992043]\n",
      "   [ 0.49754795]\n",
      "   ..., \n",
      "   [ 0.49680981]\n",
      "   [ 0.49833816]\n",
      "   [ 0.49838635]]\n",
      "\n",
      "  [[ 0.49963781]\n",
      "   [ 0.49893215]\n",
      "   [ 0.49836332]\n",
      "   ..., \n",
      "   [ 0.49892265]\n",
      "   [ 0.49985045]\n",
      "   [ 0.4989261 ]]]\n",
      "\n",
      "\n",
      " [[[ 0.49824616]\n",
      "   [ 0.49758381]\n",
      "   [ 0.49718449]\n",
      "   ..., \n",
      "   [ 0.4991987 ]\n",
      "   [ 0.49748242]\n",
      "   [ 0.49930865]]\n",
      "\n",
      "  [[ 0.49809363]\n",
      "   [ 0.49667346]\n",
      "   [ 0.49577123]\n",
      "   ..., \n",
      "   [ 0.49757129]\n",
      "   [ 0.49883398]\n",
      "   [ 0.49897665]]\n",
      "\n",
      "  [[ 0.49858898]\n",
      "   [ 0.49684972]\n",
      "   [ 0.49592471]\n",
      "   ..., \n",
      "   [ 0.49847543]\n",
      "   [ 0.49814138]\n",
      "   [ 0.49790642]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.49715868]\n",
      "   [ 0.49798518]\n",
      "   [ 0.49672723]\n",
      "   ..., \n",
      "   [ 0.49632359]\n",
      "   [ 0.49795726]\n",
      "   [ 0.4974378 ]]\n",
      "\n",
      "  [[ 0.49941549]\n",
      "   [ 0.50057304]\n",
      "   [ 0.49676087]\n",
      "   ..., \n",
      "   [ 0.49691659]\n",
      "   [ 0.4985553 ]\n",
      "   [ 0.49825007]]\n",
      "\n",
      "  [[ 0.49930525]\n",
      "   [ 0.49966744]\n",
      "   [ 0.49863368]\n",
      "   ..., \n",
      "   [ 0.49870375]\n",
      "   [ 0.49977514]\n",
      "   [ 0.49944296]]]\n",
      "\n",
      "\n",
      " [[[ 0.49793479]\n",
      "   [ 0.49745408]\n",
      "   [ 0.49715367]\n",
      "   ..., \n",
      "   [ 0.4992646 ]\n",
      "   [ 0.49747869]\n",
      "   [ 0.499075  ]]\n",
      "\n",
      "  [[ 0.49799439]\n",
      "   [ 0.49693638]\n",
      "   [ 0.4959538 ]\n",
      "   ..., \n",
      "   [ 0.49756479]\n",
      "   [ 0.49889332]\n",
      "   [ 0.49865079]]\n",
      "\n",
      "  [[ 0.49832839]\n",
      "   [ 0.49657008]\n",
      "   [ 0.49597102]\n",
      "   ..., \n",
      "   [ 0.4982793 ]\n",
      "   [ 0.49851954]\n",
      "   [ 0.49779308]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.49474528]\n",
      "   [ 0.5003494 ]\n",
      "   [ 0.49861234]\n",
      "   ..., \n",
      "   [ 0.49547836]\n",
      "   [ 0.49766669]\n",
      "   [ 0.49752688]]\n",
      "\n",
      "  [[ 0.50125605]\n",
      "   [ 0.50480616]\n",
      "   [ 0.49683836]\n",
      "   ..., \n",
      "   [ 0.49617791]\n",
      "   [ 0.49835712]\n",
      "   [ 0.49820268]]\n",
      "\n",
      "  [[ 0.50012505]\n",
      "   [ 0.5001958 ]\n",
      "   [ 0.49870577]\n",
      "   ..., \n",
      "   [ 0.49805814]\n",
      "   [ 0.49969476]\n",
      "   [ 0.49942815]]]\n",
      "\n",
      "\n",
      " ..., \n",
      " [[[ 0.4978101 ]\n",
      "   [ 0.4974584 ]\n",
      "   [ 0.49722397]\n",
      "   ..., \n",
      "   [ 0.4999299 ]\n",
      "   [ 0.49742222]\n",
      "   [ 0.49983996]]\n",
      "\n",
      "  [[ 0.49793172]\n",
      "   [ 0.49713144]\n",
      "   [ 0.49582064]\n",
      "   ..., \n",
      "   [ 0.49797252]\n",
      "   [ 0.49923247]\n",
      "   [ 0.49941131]]\n",
      "\n",
      "  [[ 0.49832165]\n",
      "   [ 0.49668032]\n",
      "   [ 0.49608964]\n",
      "   ..., \n",
      "   [ 0.49952152]\n",
      "   [ 0.49794871]\n",
      "   [ 0.49765369]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.49652717]\n",
      "   [ 0.49860242]\n",
      "   [ 0.4965823 ]\n",
      "   ..., \n",
      "   [ 0.49579123]\n",
      "   [ 0.49773023]\n",
      "   [ 0.49778801]]\n",
      "\n",
      "  [[ 0.49957997]\n",
      "   [ 0.50050867]\n",
      "   [ 0.49744123]\n",
      "   ..., \n",
      "   [ 0.49649379]\n",
      "   [ 0.49843517]\n",
      "   [ 0.49839216]]\n",
      "\n",
      "  [[ 0.49960619]\n",
      "   [ 0.49928197]\n",
      "   [ 0.49834669]\n",
      "   ..., \n",
      "   [ 0.49829292]\n",
      "   [ 0.49964923]\n",
      "   [ 0.4993625 ]]]\n",
      "\n",
      "\n",
      " [[[ 0.49811846]\n",
      "   [ 0.49746117]\n",
      "   [ 0.49684149]\n",
      "   ..., \n",
      "   [ 0.49829969]\n",
      "   [ 0.49760374]\n",
      "   [ 0.49863675]]\n",
      "\n",
      "  [[ 0.49796861]\n",
      "   [ 0.49666169]\n",
      "   [ 0.49601063]\n",
      "   ..., \n",
      "   [ 0.49714029]\n",
      "   [ 0.49881247]\n",
      "   [ 0.49799523]]\n",
      "\n",
      "  [[ 0.49837416]\n",
      "   [ 0.49671292]\n",
      "   [ 0.49570704]\n",
      "   ..., \n",
      "   [ 0.49728695]\n",
      "   [ 0.49907047]\n",
      "   [ 0.49774796]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.49663258]\n",
      "   [ 0.49877846]\n",
      "   [ 0.49696875]\n",
      "   ..., \n",
      "   [ 0.49706382]\n",
      "   [ 0.49706206]\n",
      "   [ 0.49780264]]\n",
      "\n",
      "  [[ 0.49994844]\n",
      "   [ 0.50180757]\n",
      "   [ 0.49688473]\n",
      "   ..., \n",
      "   [ 0.49657878]\n",
      "   [ 0.49835449]\n",
      "   [ 0.49833533]]\n",
      "\n",
      "  [[ 0.49949154]\n",
      "   [ 0.50001287]\n",
      "   [ 0.49844742]\n",
      "   ..., \n",
      "   [ 0.49887222]\n",
      "   [ 0.49997431]\n",
      "   [ 0.49884456]]]\n",
      "\n",
      "\n",
      " [[[ 0.49834386]\n",
      "   [ 0.49766603]\n",
      "   [ 0.49716008]\n",
      "   ..., \n",
      "   [ 0.49812973]\n",
      "   [ 0.4975099 ]\n",
      "   [ 0.49851373]]\n",
      "\n",
      "  [[ 0.49817845]\n",
      "   [ 0.49669516]\n",
      "   [ 0.49577934]\n",
      "   ..., \n",
      "   [ 0.49723357]\n",
      "   [ 0.49860853]\n",
      "   [ 0.49830738]]\n",
      "\n",
      "  [[ 0.49865299]\n",
      "   [ 0.49705222]\n",
      "   [ 0.49592319]\n",
      "   ..., \n",
      "   [ 0.49715903]\n",
      "   [ 0.4988029 ]\n",
      "   [ 0.49822628]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.49545875]\n",
      "   [ 0.49940485]\n",
      "   [ 0.49768186]\n",
      "   ..., \n",
      "   [ 0.49665958]\n",
      "   [ 0.49748877]\n",
      "   [ 0.49736714]]\n",
      "\n",
      "  [[ 0.50043076]\n",
      "   [ 0.50253165]\n",
      "   [ 0.49696359]\n",
      "   ..., \n",
      "   [ 0.49603093]\n",
      "   [ 0.49867222]\n",
      "   [ 0.4976961 ]]\n",
      "\n",
      "  [[ 0.49993587]\n",
      "   [ 0.49951774]\n",
      "   [ 0.49878958]\n",
      "   ..., \n",
      "   [ 0.49862975]\n",
      "   [ 0.49999559]\n",
      "   [ 0.49907836]]]]\n"
     ]
    }
   ],
   "source": [
    "samples = []\n",
    "for i in range(epochs):\n",
    "    train_d = True\n",
    "    train_g = True\n",
    "    keep_prob_train = 0.6\n",
    "\n",
    "    # Creating noise\n",
    "    n = np.random.uniform(0.0, 1.0, [batch_size, n_noise]).astype(np.float32)\n",
    "    # batch = [np.reshape(b, [28, 28]) for b in mnist.train.next_batch(batch_size=batch_size)[0]]\n",
    "    batch_x, _ = mnist.train.next_batch(batch_size)\n",
    "    batch_x = np.reshape(batch_x, newshape=[-1, 28, 28, 1])\n",
    "    print(batch_x.shape)\n",
    "    d_real_ls, d_fake_ls, g_ls, d_ls = sess.run(\n",
    "        [loss_d_real, loss_d_fake, loss_g, loss_d],\n",
    "        feed_dict={real_images: batch_x, noise: n, keep_prob: keep_prob_train, is_training: True}\n",
    "    )\n",
    "    d_real_ls = np.mean(d_real_ls)\n",
    "    d_fake_ls = np.mean(d_fake_ls)\n",
    "\n",
    "    g_ls = g_ls\n",
    "    d_ls = d_ls\n",
    "\n",
    "    if g_ls * 1.5 < d_ls:\n",
    "        train_g = False\n",
    "        pass\n",
    "\n",
    "    if d_ls * 2 < g_ls:\n",
    "        train_d = False\n",
    "        pass\n",
    "    if train_d:\n",
    "        sess.run(optimizer_d, feed_dict={noise: n, real_images: batch_x, keep_prob: keep_prob_train, is_training:True})\n",
    "    if train_g:\n",
    "        sess.run(optimizer_g, feed_dict={noise: n, keep_prob: keep_prob_train, is_training:True})\n",
    "        \n",
    "    # Showing sample image\n",
    "    if not i % 50:\n",
    "        gen_sample = sess.run(g, feed_dict={noise: n, keep_prob: 1.0, is_training:False})\n",
    "        print(gen_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-4d887d13d7c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Still pretty noisy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Still pretty noisy\n",
    "plt.imshow(samples[0].reshape(28, 28), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
